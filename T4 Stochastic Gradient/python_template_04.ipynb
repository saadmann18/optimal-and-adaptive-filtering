{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams.update({'legend.fontsize': 'x-large',\n",
    "                 'axes.labelsize': 'x-large',\n",
    "                 'axes.titlesize':'x-large',\n",
    "                 'xtick.labelsize':'x-large',\n",
    "                 'ytick.labelsize':'x-large'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P4 - Adaptive Interference Cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the hands-free system discussed during the theoretical part of this exercise. Investigate the usage of a fixed stepsize and a power-dependent stepsize and compare both versions. Determine the the highest stable stepsize in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(signal, block_shift):\n",
    "    \"\"\"Truncate signal to multiple of block shift.\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(signal):\n",
    "    figure, axis = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    axis.plot(signal)\n",
    "    axis.set_xlabel('Sample')\n",
    "    axis.set_ylabel('Amplitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try different filter sizes.\n",
    "# For efficient implementation always choose a power of 2!\n",
    "filter_size = 2048\n",
    "block_shift = ...\n",
    "block_size = ...\n",
    "\n",
    "# Music (mono) played back by the home server\n",
    "music = np.fromfile('music_44_1_kHz.raw', dtype=np.float32)\n",
    "music = truncate(music, block_shift)\n",
    "\n",
    "# Read the true rir (length 4096) to calculate the mismatch\n",
    "rir = np.fromfile('air1.dat', dtype=np.int16).astype(np.float)[:2048]\n",
    "rir_for_comparison = rir[:filter_size]\n",
    "scale_factor = np.max(rir_for_comparison)\n",
    "rir = rir / scale_factor\n",
    "rir_for_comparison = rir_for_comparison / scale_factor\n",
    "\n",
    "# Microphone signal for a room-impulse-response of length 2048\n",
    "mic = np.fromfile('mic_rir_2048.raw', dtype=np.float32)\n",
    "mic = truncate(mic, block_shift)\n",
    "\n",
    "# Total number of processing blocks, the first block will be half-valid\n",
    "blocks = len(mic) // block_shift\n",
    "\n",
    "# Simulated VAD\n",
    "john_start_index = 1199782 // block_shift - 1;\n",
    "john_stop_index = (1199782 + 129024) // block_shift + 1;\n",
    "john_is_speaking = np.zeros((blocks,))\n",
    "john_is_speaking[john_start_index:john_stop_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music (mono) played back by the home server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get the error message `IOPub data rate exceeded.` start the Jupyter server with\n",
    "# `jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000` or just play a\n",
    "# downsampled version of the background music.\n",
    "downsample_factor = 4\n",
    "display(Audio(music[::downsample_factor], rate=44100 / downsample_factor))\n",
    "plot_audio(music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microphone signal for a room-impulse-response of length 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get the error message `IOPub data rate exceeded.` start the Jupyter server with\n",
    "# `jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000` or just play a\n",
    "# downsampled version of the microphone signal.\n",
    "downsample_factor = 4\n",
    "display(Audio(mic[::downsample_factor], rate=44100 / downsample_factor))\n",
    "plot_audio(mic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Room impulse response (RIR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio(rir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here use the implementation of http://users.isy.liu.se/en/rt/fredrik/spcourse/multirate.pdf with additional frequency dependent step-size adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Smooth factor for energy calculation\n",
    "beta = 0.5\n",
    "\n",
    "# Step size\n",
    "power_dependent = True\n",
    "if power_dependent:\n",
    "    step_size = ...\n",
    "else:\n",
    "    step_size = ...\n",
    "\n",
    "# Allocate memory for the complex conjugated filter coefficients in frequency domain\n",
    "W_conj = np.zeros(block_size, dtype=np.complex)\n",
    "\n",
    "# Allocate memory for the concatenated blocks\n",
    "concat_blocks = np.zeros(block_size)\n",
    "\n",
    "# Allocate memory for the current power estimate per frequency bin\n",
    "power = np.zeros(block_size)\n",
    "\n",
    "# Allocate memory for the output\n",
    "output = np.zeros_like(mic)\n",
    "\n",
    "# Coefficient mismatch\n",
    "mismatch = np.zeros(blocks)\n",
    "\n",
    "# ERLE measure\n",
    "erle = np.zeros(blocks)\n",
    "\n",
    "for block_index in range(blocks):\n",
    "    # Concatenation of old and new block of observations\n",
    "    start = ... # Start index of the new block\n",
    "    stop = ... # Stop index of the new block\n",
    "    new_block = ... # New block of observations\n",
    "    concat_blocks = ... # Concatenation of old and new block\n",
    "    \n",
    "    # Convolution in frequency domain\n",
    "    ...\n",
    "    y = ... # Output block of Wiener filter\n",
    "    \n",
    "    # Correlation in frequency domain\n",
    "    ...\n",
    "    Gradient_conj = ... # \n",
    "    \n",
    "    # Power dependent step size\n",
    "    if power_dependent:\n",
    "        power = ... # Power per frequency bin\n",
    "        inverse_power = ... \n",
    "        Gradient_conj *= inverse_power\n",
    "    \n",
    "    # Filter update using the voice activity information\n",
    "    if not john_is_speaking[block_index]:\n",
    "        W_conj = ... \n",
    "        \n",
    "        # Gradient constraint:\n",
    "        ...\n",
    "        w_conj = ... # Complex conjugated filter coefficent in time domain\n",
    "        ...\n",
    "        W_conj = ...\n",
    "    \n",
    "    # Summaries\n",
    "    erle[block_index] = (\n",
    "        np.sum(np.abs(mic[block_index*block_shift:(block_index+1)*block_shift]) ** 2)\n",
    "        / np.sum(np.abs(e) ** 2)\n",
    "    )\n",
    "    w = w_conj # Coefficients are real valued\n",
    "    mismatch[block_index] = np.sum(np.abs(rir_for_comparison - w) ** 2)\n",
    "    output[start:stop] = ... # Output of the echo cancellation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of the adaptive filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get the error message `IOPub data rate exceeded.` start the Jupyter server with\n",
    "# `jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000` or just play a\n",
    "# downsampled version of the output signal of the adaptive filter.\n",
    "downsample_factor = 4\n",
    "display(Audio(output[::downsample_factor], rate=44100 / downsample_factor))\n",
    "plot_audio(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the development of the length of the error-vector(filter coefficients - coefficients ofthe room-impulse-response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(3, 1, figsize=(12, 6), squeeze=False, sharex=True)\n",
    "ax = axes[0, 0]\n",
    "ax.plot(rir)\n",
    "ax.set_ylabel('True RIR')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.plot(w)\n",
    "ax.set_ylabel('Estimated w')\n",
    "\n",
    "ax = axes[2, 0]\n",
    "ax.plot(rir - w.flatten())\n",
    "ax.set_xlabel('Filter tap')\n",
    "ax.set_ylabel('Difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the development of $ERLE_{dB}(m)=10 \\log\n",
    "\\frac{\\|\\mathbf{d}(mN)\\|^2}{\\|\\mathbf{e}(mN)\\|^2}\\text{ dB}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(3, 1, figsize=(12, 6), squeeze=False, sharex=True)\n",
    "ax = axes[0, 0]\n",
    "ax.plot(10 * np.log10(mismatch))\n",
    "ax.set_ylabel('$\\log10(||w - h||^2)$')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.plot(10 * np.log10(erle))\n",
    "ax.set_ylabel('ERLE$_{db}$')\n",
    "\n",
    "ax = axes[2, 0]\n",
    "ax.plot(john_is_speaking)\n",
    "ax.set_xlabel('Block index')\n",
    "plt.sca(axes[2, 0])\n",
    "plt.yticks(range(2), ['inactive', 'active'])\n",
    "ax.set_ylabel('Voice Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
